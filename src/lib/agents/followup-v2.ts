import OpenAI from 'openai';
import { estimateTokens, selectModel } from '../blueprints/reader';

// ğŸ”§ Blueprint ë‚´ìš© ì¸ë¼ì¸ ì²˜ë¦¬ (Vercel íŒŒì¼ì‹œìŠ¤í…œ ë¬¸ì œ í•´ê²°)
const FOLLOWUP_BASE = `# í›„ì†ì§ˆë¬¸ ìƒì„± ê¸°ë³¸ ë¸”ë£¨í”„ë¦°íŠ¸

ë‹¹ì‹ ì€ ìë™í™” ì†”ë£¨ì…˜ì„ ìœ„í•œ í›„ì†ì§ˆë¬¸ ìƒì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì‚¬ìš©ìì˜ ì´ˆê¸° ìš”ì²­ì„ ë¶„ì„í•˜ì—¬, ë§ì¶¤í˜• ìë™í™”ë¥¼ ì„¤ê³„í•˜ê¸° ìœ„í•œ í•µì‹¬ í›„ì†ì§ˆë¬¸ë“¤ì„ ìƒì„±í•˜ì„¸ìš”.

## í•µì‹¬ ì›ì¹™:
1. **ê¹Šì´ ìˆëŠ” ë§¥ë½ íŒŒì•…**: í‘œë©´ì  ìš”ì²­ ë’¤ì˜ ì§„ì§œ ëª©ì ê³¼ ì—…ë¬´ ë§¥ë½ ë°œêµ´
2. **ì‹¤í–‰ ê°€ëŠ¥ì„± í™•ë³´**: êµ¬ì²´ì ì¸ ì‹¤í–‰ ë°©ë²•ê³¼ ë„êµ¬ ì„ íƒì„ ìœ„í•œ ì •ë³´ ìˆ˜ì§‘
3. **í™•ì¥ ê°€ëŠ¥ì„± íƒìƒ‰**: ë‹¨ìˆœ ìë™í™”ë¥¼ ë” í° ì—…ë¬´ ì‹œìŠ¤í…œìœ¼ë¡œ ë°œì „ì‹œí‚¬ ìˆ˜ ìˆëŠ” ë°©í–¥ ëª¨ìƒ‰

## í•„ìˆ˜ ì§ˆë¬¸ ì˜ì—­:
- **ë°ì´í„° ì†ŒìŠ¤**: í˜„ì¬ ì–´ë–¤ ë°ì´í„°ë¥¼ ì–´ë–»ê²Œ ë‹¤ë£¨ëŠ”ì§€
- **í˜„ì¬ ì—…ë¬´**: ì§€ê¸ˆì€ ì–´ë–¤ ë°©ì‹ìœ¼ë¡œ ì²˜ë¦¬í•˜ëŠ”ì§€
- **ì„±ê³µ ê¸°ì¤€**: ì–´ë–¤ ê²°ê³¼ë¥¼ ì–»ê³  ì‹¶ì€ì§€
- **ê¸°ìˆ  ìˆ˜ì¤€**: ì–´ë–¤ ë„êµ¬ë‚˜ ë°©ë²•ì„ ì„ í˜¸í•˜ëŠ”ì§€
- **ì—…ë¬´ í™˜ê²½**: íŒ€, íšŒì‚¬, ê°œì¸ì  ìƒí™©

## ì§ˆë¬¸ í˜•ì‹:
ê° ì§ˆë¬¸ì€ ë‹¤ìŒ í˜•ì‹ì„ ë”°ë¥´ì„¸ìš”:
- **type**: "single" (ë‹¨ì¼ì„ íƒ) ë˜ëŠ” "multiple" (ë³µìˆ˜ì„ íƒ)
- **options**: ì„ íƒì§€ ë°°ì—´ (ë°˜ë“œì‹œ "ê¸°íƒ€ (ì§ì ‘ì…ë ¥)"ê³¼ "ì˜ëª¨ë¦„ (AIê°€ ì¶”ì²œ)" í¬í•¨)
- **category**: "data" | "workflow" | "goals" | "tech" | "environment"
- **importance**: "high" | "medium" | "low"

## ë°˜ë“œì‹œ í¬í•¨í•´ì•¼ í•  ì˜µì…˜:
ëª¨ë“  ì§ˆë¬¸ì˜ options ë°°ì—´ ë§ˆì§€ë§‰ì— ë°˜ë“œì‹œ ë‹¤ìŒ ë‘ ì˜µì…˜ì„ í¬í•¨í•˜ì„¸ìš”:
- "ê¸°íƒ€ (ì§ì ‘ì…ë ¥)"
- "ì˜ëª¨ë¦„ (AIê°€ ì¶”ì²œ)"`;

const FOLLOWUP_DRAFT = `# Draft ë‹¨ê³„: ì´ˆê¸° í›„ì†ì§ˆë¬¸ ìƒì„±

## ëª©í‘œ
ì‚¬ìš©ì ìš”ì²­ì„ ë¹ ë¥´ê²Œ ë¶„ì„í•˜ì—¬ 3-4ê°œì˜ í•µì‹¬ í›„ì†ì§ˆë¬¸ ì´ˆì•ˆì„ ìƒì„±í•©ë‹ˆë‹¤.

## ì ‘ê·¼ ë°©ì‹
- **ì†ë„ ìš°ì„ **: ì™„ë²½í•¨ë³´ë‹¤ëŠ” ë¹ ë¥¸ ì•„ì´ë””ì–´ ë„ì¶œ
- **í•µì‹¬ ì˜ì—­ ì»¤ë²„**: 5ê°œ ì˜ì—­(data, workflow, goals, tech, environment) ì¤‘ ê°€ì¥ ì¤‘ìš”í•œ ê²ƒë“¤ ì„ íƒ
- **ê°„ë‹¨í•œ ì˜µì…˜**: ê° ì§ˆë¬¸ë‹¹ 4-6ê°œì˜ ê¸°ë³¸ ì˜µì…˜ë§Œ ì œê³µ

## ì œì•½ ì¡°ê±´
- ìµœëŒ€ 4ê°œ ì§ˆë¬¸
- ê° ì§ˆë¬¸ë‹¹ ìµœëŒ€ 6ê°œ ì˜µì…˜ (ê¸°ë³¸ ì˜µì…˜ + "ê¸°íƒ€ (ì§ì ‘ì…ë ¥)" + "ì˜ëª¨ë¦„ (AIê°€ ì¶”ì²œ)")
- í† í° ì œí•œ: 400 í† í° ì´ë‚´`;

const FOLLOWUP_REFINE = `# Refine ë‹¨ê³„: í›„ì†ì§ˆë¬¸ ì •êµí™”

## ëª©í‘œ
Draft ë‹¨ê³„ì—ì„œ ìƒì„±ëœ ì§ˆë¬¸ë“¤ì„ ë” ì •êµí•˜ê³  ì‹¤ìš©ì ìœ¼ë¡œ ê°œì„ í•©ë‹ˆë‹¤.

## ê°œì„  í¬ì¸íŠ¸
1. **ì§ˆë¬¸ ëª…í™•ì„±**: ì‚¬ìš©ìê°€ ì´í•´í•˜ê¸° ì‰¬ìš´ í‘œí˜„ìœ¼ë¡œ ìˆ˜ì •
2. **ì˜µì…˜ ì™„ì„±ë„**: ì‹¤ì œ ìƒí™©ì„ ë°˜ì˜í•œ êµ¬ì²´ì ì¸ ì„ íƒì§€ ì¶”ê°€
3. **ì„¤ëª… ë³´ê°•**: ê° ì§ˆë¬¸ì˜ ëª©ì ê³¼ ì¤‘ìš”ì„±ì„ ëª…í™•íˆ ì„¤ëª…
4. **ë…¼ë¦¬ì  ìˆœì„œ**: ì§ˆë¬¸ ê°„ì˜ ì—°ê´€ì„±ê³¼ ìˆœì„œ ìµœì í™”

## ê°œì„  ê¸°ì¤€
- **ëª…í™•ì„±**: ì „ë¬¸ìš©ì–´ â†’ ì¼ë°˜ìš©ì–´ë¡œ ë³€ê²½
- **êµ¬ì²´ì„±**: ì¶”ìƒì  ì˜µì…˜ â†’ êµ¬ì²´ì  ìƒí™©ìœ¼ë¡œ ë³€ê²½
- **ì™„ì„±ë„**: ëˆ„ë½ëœ ì¤‘ìš” ì˜µì…˜ ì¶”ê°€
- **ì‚¬ìš©ì ì¹œí™”ì„±**: ì‚¬ìš©ì ê´€ì ì—ì„œ ì„ íƒí•˜ê¸° ì‰¬ìš´ ì˜µì…˜ êµ¬ì„±`;

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

/**
 * ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì¸í„°í˜ì´ìŠ¤
 */
interface FollowupMetrics {
  totalTokens: number;
  latencyMs: number;
  stepsUsed: string[];
  modelUsed: string;
  success: boolean;
  errors?: string[];
}

/**
 * Draft ë‹¨ê³„: ë¹ ë¥¸ ì´ˆê¸° ì§ˆë¬¸ ìƒì„±
 */
async function draftStepGen(userInput: string): Promise<{
  questions: any[];
  tokens: number;
  latency: number;
}> {
  const startTime = Date.now();
  console.log('ğŸ“ [Draft] ì´ˆê¸° ì§ˆë¬¸ ìƒì„± ì‹œì‘...');
  
  try {
    // ğŸ”§ ì¸ë¼ì¸ Blueprint ì‚¬ìš© (íŒŒì¼ì‹œìŠ¤í…œ ë¬¸ì œ í•´ê²°)
    const systemPrompt = `${FOLLOWUP_BASE}\n\n${FOLLOWUP_DRAFT}`;
    const userPrompt = `ì‚¬ìš©ì ìš”ì²­: "${userInput}"

ìœ„ ìš”ì²­ì„ ë¶„ì„í•˜ì—¬ 3-4ê°œì˜ í•µì‹¬ í›„ì†ì§ˆë¬¸ ì´ˆì•ˆì„ ìƒì„±í•˜ì„¸ìš”.
ì†ë„ë¥¼ ìš°ì„ ì‹œí•˜ì—¬ ê°„ë‹¨í•˜ê³  ëª…í™•í•œ ì§ˆë¬¸ë§Œ ë§Œë“œì„¸ìš”.`;

    // í† í° ìˆ˜ ì¶”ì • ë° ëª¨ë¸ ì„ íƒ
    const estimatedTokens = estimateTokens(systemPrompt + userPrompt);
    const model = selectModel(estimatedTokens);
    
    console.log(`ğŸ“Š [Draft] ì˜ˆìƒ í† í°: ${estimatedTokens}, ì„ íƒëœ ëª¨ë¸: ${model}`);
    
    const response = await openai.chat.completions.create({
      model,
      messages: [
        { role: 'system', content: systemPrompt },
        { role: 'user', content: userPrompt }
      ],
      max_tokens: 600,
      temperature: 0.8 // DraftëŠ” ì°½ì˜ì„± ì¤‘ì‹œ
    });

    const content = response.choices[0]?.message?.content;
    if (!content) {
      throw new Error('Draft ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤');
    }

    // JSON íŒŒì‹± (ê°œì„ ëœ ë¡œì§)
    const questions = parseQuestionsJSON(content);
    const latency = Date.now() - startTime;
    const actualTokens = response.usage?.total_tokens || estimatedTokens;
    
    console.log(`âœ… [Draft] ì™„ë£Œ - ${questions.length}ê°œ ì§ˆë¬¸, ${actualTokens} í† í°, ${latency}ms`);
    
    return {
      questions,
      tokens: actualTokens,
      latency
    };
    
  } catch (error) {
    console.error('âŒ [Draft] ì‹¤íŒ¨:', error);
    throw error;
  }
}

/**
 * Refine ë‹¨ê³„: ì§ˆë¬¸ í’ˆì§ˆ ê°œì„ 
 */
async function refineStepGen(draftQuestions: any[], userInput: string): Promise<{
  questions: any[];
  tokens: number;
  latency: number;
}> {
  const startTime = Date.now();
  console.log('ğŸ”§ [Refine] ì§ˆë¬¸ í’ˆì§ˆ ê°œì„  ì‹œì‘...');
  
  try {
    // ğŸ”§ ì¸ë¼ì¸ Blueprint ì‚¬ìš© (íŒŒì¼ì‹œìŠ¤í…œ ë¬¸ì œ í•´ê²°)
    const systemPrompt = `${FOLLOWUP_BASE}\n\n${FOLLOWUP_REFINE}`;
    const userPrompt = `ì›ë³¸ ìš”ì²­: "${userInput}"

Draft ë‹¨ê³„ì—ì„œ ìƒì„±ëœ ì§ˆë¬¸ë“¤:
${JSON.stringify(draftQuestions, null, 2)}

ìœ„ ì§ˆë¬¸ë“¤ì„ ë” ëª…í™•í•˜ê³  ì‹¤ìš©ì ìœ¼ë¡œ ê°œì„ í•´ì£¼ì„¸ìš”. 
ì§ˆë¬¸ì˜ ê°œìˆ˜ëŠ” ìœ ì§€í•˜ë˜, í‘œí˜„ê³¼ ì˜µì…˜ë“¤ì„ ë” êµ¬ì²´ì ì´ê³  ì‚¬ìš©ì ì¹œí™”ì ìœ¼ë¡œ ë§Œë“œì„¸ìš”.`;

    // í† í° ìˆ˜ ì¶”ì • ë° ëª¨ë¸ ì„ íƒ
    const estimatedTokens = estimateTokens(systemPrompt + userPrompt);
    const model = selectModel(estimatedTokens);
    
    console.log(`ğŸ“Š [Refine] ì˜ˆìƒ í† í°: ${estimatedTokens}, ì„ íƒëœ ëª¨ë¸: ${model}`);
    
    const response = await openai.chat.completions.create({
      model,
      messages: [
        { role: 'system', content: systemPrompt },
        { role: 'user', content: userPrompt }
      ],
      max_tokens: 800,
      temperature: 0.3 // Refineì€ ì •í™•ì„± ì¤‘ì‹œ
    });

    const content = response.choices[0]?.message?.content;
    if (!content) {
      throw new Error('Refine ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤');
    }

    // JSON íŒŒì‹±
    const questions = parseQuestionsJSON(content);
    const latency = Date.now() - startTime;
    const actualTokens = response.usage?.total_tokens || estimatedTokens;
    
    console.log(`âœ… [Refine] ì™„ë£Œ - ${questions.length}ê°œ ì§ˆë¬¸, ${actualTokens} í† í°, ${latency}ms`);
    
    return {
      questions,
      tokens: actualTokens,
      latency
    };
    
  } catch (error) {
    console.error('âŒ [Refine] ì‹¤íŒ¨:', error);
    throw error;
  }
}

/**
 * ê°œì„ ëœ JSON íŒŒì‹± í•¨ìˆ˜
 */
function parseQuestionsJSON(content: string): any[] {
  try {
    // 1ì°¨ ì‹œë„: ì§ì ‘ íŒŒì‹±
    const parsed = JSON.parse(content);
    return parsed.questions || [];
  } catch (firstError) {
    console.log('ğŸ”„ [JSON] 1ì°¨ íŒŒì‹± ì‹¤íŒ¨, ì •ë¦¬ í›„ ì¬ì‹œë„...');
    
    try {
      // 2ì°¨ ì‹œë„: ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°
      let cleanContent = content;
      if (content.includes('```json')) {
        const startIndex = content.indexOf('```json') + 7;
        const endIndex = content.lastIndexOf('```');
        cleanContent = content.substring(startIndex, endIndex).trim();
      }
      
      // 3ì°¨ ì‹œë„: ì¶”ê°€ ì •ë¦¬
      cleanContent = cleanContent
        .replace(/[\u201C\u201D]/g, '"')  // ìŠ¤ë§ˆíŠ¸ ë”°ì˜´í‘œ
        .replace(/[\u2018\u2019]/g, "'")  // ìŠ¤ë§ˆíŠ¸ ì•„í¬ìŠ¤íŠ¸ë¡œí”¼
        .replace(/,(\s*[}\]])/g, '$1')   // trailing comma ì œê±°
        .trim();
      
      const parsed = JSON.parse(cleanContent);
      return parsed.questions || [];
      
    } catch (secondError) {
      console.error('âŒ [JSON] 2ì°¨ íŒŒì‹±ë„ ì‹¤íŒ¨, í´ë°± ì§ˆë¬¸ ë°˜í™˜');
      
      // í´ë°±: ê¸°ë³¸ ì§ˆë¬¸ ë°˜í™˜
      return getFallbackQuestions();
    }
  }
}

/**
 * í´ë°± ì§ˆë¬¸ë“¤ (JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ)
 */
function getFallbackQuestions(): any[] {
  return [
    {
      key: "data_source",
      question: "í˜„ì¬ ì²˜ë¦¬í•˜ëŠ” ë°ì´í„°ëŠ” ì£¼ë¡œ ì–´ë””ì—ì„œ ì˜¤ë‚˜ìš”?",
      type: "single",
      options: ["ì—‘ì…€/êµ¬ê¸€ì‹œíŠ¸", "ë°ì´í„°ë² ì´ìŠ¤", "ì›¹ì‚¬ì´íŠ¸", "ì´ë©”ì¼", "ê¸°íƒ€ (ì§ì ‘ì…ë ¥)", "ì˜ëª¨ë¦„ (AIê°€ ì¶”ì²œ)"],
      category: "data",
      importance: "high",
      description: "ë°ì´í„° ì†ŒìŠ¤ íŒŒì•…"
    },
    {
      key: "current_workflow",
      question: "í˜„ì¬ëŠ” ì´ ì‘ì—…ì„ ì–´ë–»ê²Œ ì²˜ë¦¬í•˜ê³  ê³„ì‹ ê°€ìš”?",
      type: "single",
      options: ["ìˆ˜ë™ìœ¼ë¡œ ì§ì ‘", "ê°„ë‹¨í•œ ë„êµ¬ ì‚¬ìš©", "ë³µì¡í•œ ì‹œìŠ¤í…œ ì‚¬ìš©", "ì•„ì§ ì‹œì‘ ì•ˆí•¨", "ê¸°íƒ€ (ì§ì ‘ì…ë ¥)", "ì˜ëª¨ë¦„ (AIê°€ ì¶”ì²œ)"],
      category: "workflow",
      importance: "high",
      description: "í˜„ì¬ ì—…ë¬´ ë°©ì‹ íŒŒì•…"
    },
    {
      key: "success_criteria",
      question: "ì´ ìë™í™”ë¥¼ í†µí•´ ì–»ê³  ì‹¶ì€ ê°€ì¥ ì¤‘ìš”í•œ ê²°ê³¼ëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
      type: "single",
      options: ["ì‹œê°„ ì ˆì•½", "ì •í™•ë„ í–¥ìƒ", "ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§", "ë°ì´í„° ì¸ì‚¬ì´íŠ¸", "ê¸°íƒ€ (ì§ì ‘ì…ë ¥)", "ì˜ëª¨ë¦„ (AIê°€ ì¶”ì²œ)"],
      category: "goals",
      importance: "high",
      description: "ì„±ê³µ ê¸°ì¤€ ì„¤ì •"
    }
  ];
}

/**
 * ë©”ì¸ 2-Step í›„ì†ì§ˆë¬¸ ìƒì„± í•¨ìˆ˜
 */
export async function generate2StepFollowup(userInput: string): Promise<{
  questions: any[];
  metrics: FollowupMetrics;
}> {
  const overallStartTime = Date.now();
  const metrics: FollowupMetrics = {
    totalTokens: 0,
    latencyMs: 0,
    stepsUsed: [],
    modelUsed: 'gpt-4o-mini',
    success: false,
    errors: []
  };
  
  try {
    console.log('ğŸš€ [2-Step] í›„ì†ì§ˆë¬¸ ìƒì„± ì‹œì‘');
    
    // Step 1: Draft
    const draftResult = await draftStepGen(userInput);
    metrics.stepsUsed.push('draft');
    metrics.totalTokens += draftResult.tokens;
    
    // Step 2: Refine
    const refineResult = await refineStepGen(draftResult.questions, userInput);
    metrics.stepsUsed.push('refine');
    metrics.totalTokens += refineResult.tokens;
    
    // ë©”íŠ¸ë¦­ ì™„ì„±
    metrics.latencyMs = Date.now() - overallStartTime;
    metrics.success = true;
    
    console.log(`âœ… [2-Step] ì™„ë£Œ - ì´ ${metrics.totalTokens} í† í°, ${metrics.latencyMs}ms`);
    console.log(`ğŸ’° [ë¹„ìš©] ì˜ˆìƒ ì ˆì•½: ${((metrics.totalTokens * 0.00015) * 100).toFixed(2)}% (ê¸°ì¡´ 4o ëŒ€ë¹„)`);
    
    return {
      questions: refineResult.questions,
      metrics
    };
    
  } catch (error) {
    metrics.success = false;
    metrics.errors = [error instanceof Error ? error.message : String(error)];
    metrics.latencyMs = Date.now() - overallStartTime;
    
    console.error('âŒ [2-Step] ì‹¤íŒ¨:', error);
    
    // ì™„ì „ ì‹¤íŒ¨ ì‹œì—ë„ í´ë°± ì§ˆë¬¸ ë°˜í™˜
    return {
      questions: getFallbackQuestions(),
      metrics
    };
  }
}